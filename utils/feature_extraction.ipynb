{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def conll_to_tokens(path_to_dataset, encoding='utf8'):\n",
    "#     features = []\n",
    "    labelled_tokens = []\n",
    "    sent = []\n",
    "    for line in open(path_to_dataset, 'r', encoding=encoding).readlines()[:20]:\n",
    "#         if line == '':\n",
    "#             features.append(sent)\n",
    "#             sent = []\n",
    "#         else:\n",
    "#             chunks = line.split()\n",
    "#             word_features = [chunks[0], chunks[2]]\n",
    "# #             print(chunks[2:])\n",
    "#             sent.append(([word_features], chunks[1]))\n",
    "#     if len(sent) > 0:\n",
    "#         features.append(sent)\n",
    "        chunks = line.split()\n",
    "        word_features = [chunks[0], chunks[2]]\n",
    "        labelled_tokens.append(([word_features], chunks[1]))\n",
    "    return labelled_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word2vec = {} # dictionary of word2vec representation of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "symbols = {} # dictionary of one-hot encoded symbols"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "pos_tags = {} # dictionary of word2vec representation of pos tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "affix_ids = {} # dictionary of one-hot encoded suffixes and prefixes (word2vec???)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def extract_features(labelled_tokens):  # @tokens - list of tokens, containing the tokens and its pos tag\n",
    "    \n",
    "    data = []\n",
    "    for token, label in labelled_tokens:\n",
    "        for symbol in token:\n",
    "            features = []\n",
    "            features.extend(word2vec[token])        # token word2vec\n",
    "            features.extend(pos_tags[label])        # label word2vec\n",
    "            features.extend(suffix_ids[token[-3:]]) # suffix code\n",
    "            features.extend(suffix_ids[token[:3]])  # prefix code\n",
    "            features.extend(symbols[symbol])        # symbol code\n",
    "            features.append(symbol.isupper())       # upper/lower case\n",
    "            features.append(symbol.isalpha())       # letter/symbol\n",
    "            features.append(token[0].isupper())     # word's first letter's case\n",
    "            features.append(token.isupper())        # word is all upper or not\n",
    "            data.append((features, label))\n",
    "    return data\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "features = tokens_from_conll('ru1.conll.txt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[([['На', 'PR']], 'O'),\n",
       " ([['севере', 'S']], 'O'),\n",
       " ([['граничит', 'V']], 'O'),\n",
       " ([['с', 'PR']], 'O'),\n",
       " ([['Латвией', 'S']], 'LOC'),\n",
       " ([[',', 'PUNCT']], 'O'),\n",
       " ([['на', 'PR']], 'O'),\n",
       " ([['востоке', 'S']], 'O'),\n",
       " ([['--', 'PUNCT']], 'O'),\n",
       " ([['с', 'PR']], 'O'),\n",
       " ([['Белоруссией', 'S']], 'LOC'),\n",
       " ([[',', 'PUNCT']], 'O'),\n",
       " ([['на', 'PR']], 'O'),\n",
       " ([['юго-западе', 'S']], 'O'),\n",
       " ([['--', 'PUNCT']], 'O'),\n",
       " ([['c', 'PR']], 'O'),\n",
       " ([['Польшей', 'S']], 'LOC'),\n",
       " ([['и', 'CONJ']], 'O'),\n",
       " ([['Калининградской', 'A']], 'LOC'),\n",
       " ([['областью', 'S']], 'LOC')]"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Symbol:\n",
    "    \n",
    "    symbols = {'UNKN':[0.0, 0.0, 0.0]}   # dict of symbol one-hot codes\n",
    "                    \n",
    "    def __init__(self, symbol):\n",
    "        self.value = symbol\n",
    "        self.encoding = Symbol.symbols.get(symbol, Symbol.symbols['UNKN'])\n",
    "        self.alphabetic = 1.0 if symbol.isalpha() else 0.0\n",
    "    \n",
    "    def get_features(self):\n",
    "        x = self.encoding[:]\n",
    "        x.append(self.alphabetic)\n",
    "        return x\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "class Token:\n",
    "    \n",
    "    tokens = {'UNKN':[0.0, 0.0, 0.0]}      # token word encodings\n",
    "    tags = {'UNKN':[0.0, 0.0, 0.0]}        # tag encodings\n",
    "    affixes = {'UNKN':[0.0, 0.0, 0.0]}     # affix encodings, (should we store code for prefixes and suffixes in the same dict?)\n",
    "    \n",
    "    def __init__(self, token, tag=None):\n",
    "        \n",
    "        self.value = token\n",
    "        self.encoding = Token.tokens.get(token, Token.tokens['UNKN'])\n",
    "        self.tag_value = tag\n",
    "        self.tag_encoding = Token.tags.get(tag, Token.tags['UNKN'])\n",
    "        self.suffix = Token.affixes.get(token[-3:], Token.affixes['UNKN'])\n",
    "        self.prefix = Token.affixes.get(token[3:], Token.affixes['UNKN'])\n",
    "        self.case = 1.0 if token[0].isupper() else 0.0\n",
    "        self.upper = 1.0 if token.isupper() else 0.0\n",
    "        self.symbols = list([Symbol(s) for s in token])\n",
    "        \n",
    "    def get_features(self):\n",
    "        return self.encoding + self.tag_encoding + self.suffix + self.prefix + [self.case , self.upper]\n",
    "    \n",
    "    def get_symbol_features(self):\n",
    "        return list([s.get_features() + self.get_features() for s in self.symbols])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "S = Symbol('a')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 1.0]\n"
     ]
    }
   ],
   "source": [
    "print(S.get_features())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "t = Token('Привет')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0]"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.get_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0],\n",
       " [0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  0.0,\n",
       "  1.0,\n",
       "  0.0]]"
      ]
     },
     "execution_count": 107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "t.get_symbol_features()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
